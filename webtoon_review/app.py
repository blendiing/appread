import streamlit as st
from google_play_scraper import reviews, Sort
import pandas as pd
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re
import os
from io import BytesIO
from datetime import datetime

# ----------------------------
# í˜ì´ì§€ ì„¤ì •
# ----------------------------
st.set_page_config(
    page_title="ê²½ìŸì‚¬ ì•± ë¦¬ë·° ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ----------------------------
# í°íŠ¸ ê²½ë¡œ ì„¤ì • (ì‹œìŠ¤í…œ í°íŠ¸ ì‚¬ìš©)
# ----------------------------
def get_font_path():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°"""
    possible_paths = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf",
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
    ]
    for path in possible_paths:
        if os.path.exists(path):
            return path
    return None

FONT_PATH = get_font_path()

# ----------------------------
# ì•± ëª©ë¡ ì •ì˜
# ----------------------------
APP_LIST = {
    "ë„¤ì´ë²„ ì›¹íˆ°": "com.nhn.android.webtoon",
    "ì¹´ì¹´ì˜¤í˜ì´ì§€": "com.kakaopage.app",
    "ë ˆì§„ì½”ë¯¹ìŠ¤": "com.lezhin.comics",
    "ë¦¬ë””ë¶ìŠ¤": "com.initialcoms.ridi",
}

# ----------------------------
# ë¶ˆìš©ì–´ ì •ì˜
# ----------------------------
STOPWORDS = {
    "ë„ˆë¬´", "ì •ë§", "ì§„ì§œ", "ë§¤ìš°", "ì•„ì£¼", "ì™„ì „", "ë˜ê²Œ", "ê½¤", "ì¢€", "ì•½ê°„", "ì‚´ì§",
    "ì›¹íˆ°", "ê·¸ëƒ¥", "ì´ê±°", "ì €ê±°", "ê·¸ê²ƒ", "ì´ê²ƒ", "ì €ê²ƒ", "í•˜ëŠ”", "ìˆëŠ”", "ì—†ëŠ”",
    "í•´ì„œ", "í•˜ê³ ", "í•´ìš”", "í•©ë‹ˆë‹¤", "ì…ë‹ˆë‹¤", "ìˆì–´ìš”", "ì—†ì–´ìš”", "ê°™ì•„ìš”",
    "ì´ëŸ°", "ì €ëŸ°", "ê·¸ëŸ°", "ì–´ë–¤", "ë¬´ìŠ¨", "ì™œ", "ì–´ë””", "ì–¸ì œ", "ì–´ë–»ê²Œ",
    "ê·¼ë°", "ê·¸ë˜ì„œ", "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜", "ê·¸ë¦¬ê³ ", "ë˜í•œ", "ê·¸ë˜ë„",
    "ìˆì–´", "ì—†ì–´", "í•˜ë©´", "ì´ìš©", "ì‚¬ìš©", "ì •ë„", "ì´ìƒ", "ê³„ì†", "ë‹¤ì‹œ", "ì²˜ìŒ", "ë§ˆì§€ë§‰"
}

# ----------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ----------------------------
def simple_tokenizer(text):
    """ì •ê·œì‹ ê¸°ë°˜ í•œê¸€ í† í¬ë‚˜ì´ì €"""
    tokens = re.findall(r"[ê°€-í£]{2,}", str(text))
    tokens = [t for t in tokens if t not in STOPWORDS and len(t) >= 2]
    return tokens

@st.cache_data(ttl=7200, show_spinner=False)
def get_reviews_cached(app_id, count=1000):
    """Google Play ë¦¬ë·° ìˆ˜ì§‘ (ìºì‹±)"""
    result = []
    continuation_token = None
    
    try:
        while len(result) < count:
            batch_size = min(100, count - len(result))
            review_batch, continuation_token = reviews(
                app_id,
                lang="ko",
                country="kr",
                sort=Sort.NEWEST,
                count=batch_size,
                continuation_token=continuation_token
            )
            result.extend(review_batch)
            
            if not continuation_token:
                break
    except Exception as e:
        st.error(f"ë¦¬ë·° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()
    
    df = pd.DataFrame(result)
    if not df.empty:
        df["at"] = pd.to_datetime(df["at"])
        df["content"] = df["content"].astype(str)
    
    return df

@st.cache_data(ttl=86400, show_spinner=False)
def get_default_data():
    """
    ë””í´íŠ¸ ë°ì´í„° ë¡œë“œ
    - ë„¤ì´ë²„ ì›¹íˆ° ë¦¬ë·°
    - 2025ë…„ 1ì›” 19ì¼ 19:00 ì´ì „ ë°ì´í„° 1000ê±´
    """
    cutoff_date = datetime(2025, 1, 19, 19, 0, 0)
    
    df = get_reviews_cached("com.nhn.android.webtoon", count=1500)
    
    if not df.empty:
        # ê¸°ì¤€ ì‹œê°„ ì´ì „ ë°ì´í„°ë§Œ í•„í„°ë§
        df = df[df["at"] < cutoff_date]
        # ìµœì‹ ìˆœ ì •ë ¬ í›„ 1000ê±´ë§Œ
        df = df.sort_values(by="at", ascending=False).head(1000)
    
    return df

@st.cache_data(ttl=7200, show_spinner=False)
def extract_keywords_cached(contents_tuple):
    """í‚¤ì›Œë“œ ì¶”ì¶œ (ìºì‹±)"""
    tokens = []
    for text in contents_tuple:
        tokens += simple_tokenizer(text)
    return tokens

@st.cache_data(ttl=7200, show_spinner=False)
def generate_wordcloud_image(word_freq_tuple, font_path):
    """ì›Œë“œí´ë¼ìš°ë“œë¥¼ ì´ë¯¸ì§€ë¡œ ìƒì„±"""
    word_freq = dict(word_freq_tuple)
    
    try:
        wc = WordCloud(
            font_path=font_path,
            width=800,
            height=400,
            background_color="white",
            colormap="viridis",
            max_words=50
        )
        wc.generate_from_frequencies(word_freq)
        
        img_buffer = BytesIO()
        wc.to_image().save(img_buffer, format='PNG')
        img_buffer.seek(0)
        
        return img_buffer.getvalue()
    except Exception as e:
        return None

@st.cache_data(ttl=7200, show_spinner=False)
def calculate_co_occurrence(contents_tuple):
    """ì—°ê´€ì–´ ê³„ì‚° (ìºì‹±)"""
    co_occurrence = {}
    for text in contents_tuple:
        tokens = simple_tokenizer(text)
        for i in range(len(tokens) - 1):
            a, b = tokens[i], tokens[i + 1]
            if a != b:
                co_occurrence.setdefault(a, []).append(b)
    return co_occurrence

def display_analysis(df, app_name="", data_info=""):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    
    if df.empty:
        st.error("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì •ë³´ í‘œì‹œ
    if data_info:
        st.info(data_info)
    
    st.success(f"âœ… **{len(df):,}ê±´** ë¦¬ë·° ë¶„ì„ ì™„ë£Œ! {f'({app_name})' if app_name else ''}")
    
    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ í†µê³„", "ğŸ’¬ í‚¤ì›Œë“œ", "ğŸ”— ì—°ê´€ì–´", "ğŸ“ ë¦¬ë·°"])
    
    # ----------------------------
    # íƒ­ 1: í†µê³„
    # ----------------------------
    with tab1:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ë¦¬ë·°", f"{len(df):,}")
        with col2:
            st.metric("í‰ê·  í‰ì ", f"{df['score'].mean():.1f}â­")
        with col3:
            recent = df[df["at"] >= df["at"].max() - pd.Timedelta(days=7)]
            st.metric("ìµœê·¼ 7ì¼", f"{len(recent):,}")
        with col4:
            ratio = (df["score"] == 5).sum() / len(df) * 100
            st.metric("5ì  ë¹„ìœ¨", f"{ratio:.0f}%")
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ—“ï¸ ë‚ ì§œë³„ ë¦¬ë·°")
            daily = df.groupby(df["at"].dt.date).size()
            st.line_chart(daily)
        
        with col2:
            st.subheader("â­ í‰ì  ë¶„í¬")
            scores = df["score"].value_counts().sort_index()
            st.bar_chart(scores)
    
    # ----------------------------
    # íƒ­ 2: í‚¤ì›Œë“œ
    # ----------------------------
    with tab2:
        st.subheader("ğŸ’¬ ì£¼ìš” í‚¤ì›Œë“œ TOP 30")
        
        contents_tuple = tuple(df["content"].tolist())
        tokens = extract_keywords_cached(contents_tuple)
        counter = Counter(tokens)
        common_words = counter.most_common(30)
        
        if common_words:
            word_freq_tuple = tuple(common_words)
            img_bytes = generate_wordcloud_image(word_freq_tuple, FONT_PATH)
            
            if img_bytes:
                st.image(img_bytes, use_container_width=True)
            else:
                st.warning("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ë¶ˆê°€. ì•„ë˜ í‘œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            keyword_df = pd.DataFrame(common_words, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])
            
            col1, col2 = st.columns(2)
            with col1:
                st.dataframe(keyword_df.head(15), use_container_width=True, hide_index=True)
            with col2:
                st.dataframe(keyword_df.tail(15), use_container_width=True, hide_index=True)
    
    # ----------------------------
    # íƒ­ 3: ì—°ê´€ì–´
    # ----------------------------
    with tab3:
        st.subheader("ğŸ”— í‚¤ì›Œë“œ ì—°ê´€ ë‹¨ì–´")
        
        contents_tuple = tuple(df["content"].tolist())
        co_occurrence = calculate_co_occurrence(contents_tuple)
        
        related_words = []
        for k, v in counter.most_common(20):
            related = Counter(co_occurrence.get(k, [])).most_common(5)
            related_words.append({
                "í‚¤ì›Œë“œ": k,
                "ë¹ˆë„": v,
                "ì—°ê´€ë‹¨ì–´": ", ".join([f"{r[0]}({r[1]})" for r in related]) if related else "-"
            })
        
        st.dataframe(pd.DataFrame(related_words), use_container_width=True, hide_index=True)
    
    # ----------------------------
    # íƒ­ 4: ë¦¬ë·° ì›ë¬¸
    # ----------------------------
    with tab4:
        st.subheader("ğŸ“ ë¦¬ë·° ì›ë¬¸")
        
        col1, col2 = st.columns(2)
        with col1:
            score_filter = st.multiselect("í‰ì ", [1,2,3,4,5], default=[1,2,3,4,5])
        with col2:
            keyword = st.text_input("ê²€ìƒ‰")
        
        filtered = df[df["score"].isin(score_filter)]
        if keyword:
            filtered = filtered[filtered["content"].str.contains(keyword, na=False)]
        
        st.write(f"**{len(filtered):,}ê±´**")
        
        display_df = filtered.head(100)[["at", "score", "content"]].copy()
        display_df["at"] = display_df["at"].dt.strftime("%Y-%m-%d")
        display_df.columns = ["ë‚ ì§œ", "í‰ì ", "ë‚´ìš©"]
        st.dataframe(display_df, use_container_width=True, hide_index=True)

# ----------------------------
# ë©”ì¸ UI
# ----------------------------
st.title("ğŸ“Š ê²½ìŸì‚¬ ì•± ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.caption("Google Play Store ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ ê²½ìŸì‚¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.")

# ----------------------------
# ì‚¬ì´ë“œë°”
# ----------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    st.markdown("---")
    
    # ëª¨ë“œ ì„ íƒ
    mode = st.radio(
        "ë¶„ì„ ëª¨ë“œ",
        ["ğŸ“Œ ê¸°ë³¸ ë°ì´í„° ë³´ê¸°", "ğŸ”„ ìƒˆë¡œ ìˆ˜ì§‘í•˜ê¸°"],
        index=0
    )
    
    if mode == "ğŸ”„ ìƒˆë¡œ ìˆ˜ì§‘í•˜ê¸°":
        st.markdown("---")
        
        # ì•± ì„ íƒ
        selected_app = st.selectbox(
            "ì•± ì„ íƒ",
            options=list(APP_LIST.keys()),
            index=0
        )
        
        # ë˜ëŠ” ì§ì ‘ ì…ë ¥
        custom_app_id = st.text_input(
            "ë˜ëŠ” ì•± ID ì§ì ‘ ì…ë ¥",
            placeholder="com.example.app"
        )
        
        review_count = st.select_slider(
            "ìˆ˜ì§‘í•  ë¦¬ë·° ìˆ˜",
            options=[100, 300, 500, 700, 1000],
            value=500
        )
        
        collect_btn = st.button("ğŸ” ë°ì´í„° ìˆ˜ì§‘", type="primary", use_container_width=True)
    else:
        collect_btn = False
    
    st.markdown("---")
    st.markdown("##### ğŸ“Œ ì§€ì› ì•± ëª©ë¡")
    for name in APP_LIST.keys():
        st.caption(f"â€¢ {name}")

# ----------------------------
# ë©”ì¸ ì½˜í…ì¸ 
# ----------------------------
if mode == "ğŸ“Œ ê¸°ë³¸ ë°ì´í„° ë³´ê¸°":
    
    with st.spinner("ğŸ“¥ ê¸°ë³¸ ë°ì´í„° ë¡œë”© ì¤‘..."):
        df = get_default_data()
    
    display_analysis(
        df, 
        app_name="ë„¤ì´ë²„ ì›¹íˆ°",
        data_info="ğŸ“Œ **ê¸°ë³¸ ë°ì´í„°**: ë„¤ì´ë²„ ì›¹íˆ° ë¦¬ë·° 1,000ê±´ (2025.01.19 19:00 ê¸°ì¤€ ì´ì „ ë°ì´í„°)"
    )

else:  # ìƒˆë¡œ ìˆ˜ì§‘í•˜ê¸°
    if collect_btn:
        # ì•± ID ê²°ì •
        if custom_app_id:
            app_id = custom_app_id
            app_name = custom_app_id
        else:
            app_id = APP_LIST[selected_app]
            app_name = selected_app
        
        with st.spinner(f"ğŸ“¥ {app_name} ë¦¬ë·° ìˆ˜ì§‘ ì¤‘... ({review_count}ê±´)"):
            df = get_reviews_cached(app_id, count=review_count)
            df = df.sort_values(by="at", ascending=False)
            st.session_state["collected_df"] = df
            st.session_state["collected_app"] = app_name
    
    # ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if st.session_state.get("collected_df") is not None and not st.session_state["collected_df"].empty:
        df = st.session_state["collected_df"]
        app_name = st.session_state.get("collected_app", "")
        display_analysis(df, app_name)
    else:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ì•±ì„ ì„ íƒí•˜ê³  **ë°ì´í„° ìˆ˜ì§‘** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!")
        
        st.markdown("""
        ### ğŸ¯ ë¶„ì„ ê°€ëŠ¥ í•­ëª©
        - ğŸ“ˆ **í†µê³„**: í‰ì  ë¶„í¬, ë‚ ì§œë³„ ì¶”ì´
        - ğŸ’¬ **í‚¤ì›Œë“œ**: ìì£¼ ì–¸ê¸‰ë˜ëŠ” ë‹¨ì–´ TOP 30
        - ğŸ”— **ì—°ê´€ì–´**: í‚¤ì›Œë“œ ê°„ ê´€ê³„ ë¶„ì„
        - ğŸ“ **ë¦¬ë·° ì›ë¬¸**: í•„í„°ë§ & ê²€ìƒ‰
        """)

# ----------------------------
# í‘¸í„°
# ----------------------------
st.markdown("---")
st.caption("Made with â¤ï¸ using Streamlit | ë°ì´í„°: Google Play Store")
